# -*- coding: utf-8 -*-
"""Untitled8.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1mgLK_nNUkS4Wk9B4t-X-5ixVwOhATkVY
"""

# ============================================================
# Assignment 2 - FAST VERSION (Graph Sampling Included)
# Full Pipeline â€” Ready For Google Colab
# ============================================================

!pip install networkx matplotlib scikit-learn python-louvain tqdm

import networkx as nx
import matplotlib.pyplot as plt
import numpy as np
import random
from google.colab import files
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report
from community import community_louvain
from tqdm import tqdm


# -------------------------------------------------------------
# 1) Upload the Dataset
# -------------------------------------------------------------
print("Upload the facebook_combined.txt.gz file")
uploaded = files.upload()

filename = list(uploaded.keys())[0]
print("Using file:", filename)


# -------------------------------------------------------------
# 2) Load Graph
# -------------------------------------------------------------
print("\nLoading graph...")
G = nx.read_edgelist(filename)
print("Original Graph Loaded:")
print("Nodes:", G.number_of_nodes())
print("Edges:", G.number_of_edges())


# -------------------------------------------------------------
# 3) Reduce Graph Size for Fast Performance (Sampling)
# -------------------------------------------------------------
print("\nReducing graph size for faster processing...")

TARGET_NODES = 800

start_node = list(G.nodes())[0]
sample_nodes = set([start_node])
queue = [start_node]

while len(sample_nodes) < TARGET_NODES and queue:
    node = queue.pop(0)
    for neigh in list(G.neighbors(node)):
        if len(sample_nodes) >= TARGET_NODES:
            break
        if neigh not in sample_nodes:
            sample_nodes.add(neigh)
            queue.append(neigh)

G = G.subgraph(sample_nodes).copy()

print("\nSampled Graph:")
print("Nodes:", G.number_of_nodes())
print("Edges:", G.number_of_edges())


# -------------------------------------------------------------
# 4) Extract Graph Features
# -------------------------------------------------------------
def extract_features(graph):
    print("\nExtracting features...")

    degree = dict(graph.degree())
    clustering = nx.clustering(graph)
    pagerank = nx.pagerank(graph)
    closeness = nx.closeness_centrality(graph)
    betweenness = nx.betweenness_centrality(graph)
    eigenvector = nx.eigenvector_centrality(graph, max_iter=500)

    print("Detecting communities (Louvain)...")
    communities = community_louvain.best_partition(graph)

    X = []
    nodes = list(graph.nodes())

    for n in nodes:
        X.append([
            degree[n],
            clustering[n],
            pagerank[n],
            closeness[n],
            betweenness[n],
            eigenvector[n],
            communities[n],
        ])

    return np.array(X), nodes


X, nodes = extract_features(G)


# -------------------------------------------------------------
# 5) Assign Bot Nodes (5%)
# -------------------------------------------------------------
num_bots = int(0.05 * len(nodes))
bot_nodes = random.sample(nodes, num_bots)

y = np.array([1 if n in bot_nodes else 0 for n in nodes])

print("\nBots assigned:", num_bots)


# -------------------------------------------------------------
# 6) Train Baseline Model
# -------------------------------------------------------------
clf = RandomForestClassifier(n_estimators=150)
clf.fit(X, y)

baseline_pred = clf.predict(X)
baseline_acc = accuracy_score(y, baseline_pred)

print("\n===== Baseline Accuracy =====")
print(baseline_acc)
print(classification_report(y, baseline_pred))


# -------------------------------------------------------------
# 7) Structural Evasion Attack
# -------------------------------------------------------------
print("\nApplying Structural Evasion Attack...")
G_evasion = G.copy()

for b in bot_nodes:
    neighbors = list(G_evasion.neighbors(b))
    remove_k = min(5, len(neighbors))
    for r in random.sample(neighbors, remove_k):
        G_evasion.remove_edge(b, r)

Xevasion, _ = extract_features(G_evasion)
evasion_pred = clf.predict(Xevasion)
evasion_acc = accuracy_score(y, evasion_pred)

print("\n===== After Structural Evasion =====")
print(evasion_acc)
print(classification_report(y, evasion_pred))


# -------------------------------------------------------------
# 8) Graph Poisoning Attack
# -------------------------------------------------------------
print("\nApplying Graph Poisoning Attack...")
G_poison = G.copy()

top_nodes = [n for n, d in sorted(G_poison.degree(), key=lambda x: -x[1])[:100]]

for b in bot_nodes:
    for t in random.sample(top_nodes, 5):
        G_poison.add_edge(b, t)

Xpoison, _ = extract_features(G_poison)
poison_pred = clf.predict(Xpoison)
poison_acc = accuracy_score(y, poison_pred)

print("\n===== After Graph Poisoning =====")
print(poison_acc)
print(classification_report(y, poison_pred))


# -------------------------------------------------------------
# 9) Visualization
# -------------------------------------------------------------
def plot_graph(graph, title):
    plt.figure(figsize=(10, 7))
    pos = nx.spring_layout(graph, seed=42)
    nx.draw(graph, pos, node_size=10, edge_color="gray")
    plt.title(title)
    plt.show()

print("\nDrawing Graphs...")
plot_graph(G, "Original Sampled Graph")
plot_graph(G_evasion, "After Structural Evasion Attack")
plot_graph(G_poison, "After Graph Poisoning Attack")


# -------------------------------------------------------------
# 10) Final Comparison
# -------------------------------------------------------------
print("\n===============================")
print("     FINAL PERFORMANCE")
print("===============================")
print("Baseline Accuracy:       ", baseline_acc)
print("After Structural Evasion:", evasion_acc)
print("After Graph Poisoning:   ", poison_acc)